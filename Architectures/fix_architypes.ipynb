{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth_validation (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "### ----- ERROR HANDLING\n",
    "function do_activations_match_depth(depth, activation)\n",
    "    \"\"\"Error handling, if using multiple activations\"\"\"\n",
    "    if length(activation) != (depth - 2)\n",
    "        error(\"$(length(activation)) activations provided, but $(depth - 2) layers activate.\\nBeware: identity is used for last layer - DO NOT PROVIDE FOR LAST LAYER\")\n",
    "    end\n",
    "end\n",
    "\n",
    "function depth_validation(depth)\n",
    "    if depth < 3\n",
    "        error(\"Depth must be at least 3 to form an ANN.\\nBeware that 'depth' refers to ALL layers.\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "construct_model (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Different Architecture types for varrying data\n",
    "### Author: Axel Bjarkar\n",
    "\n",
    "# ?model_architype(architype, dimIN, dimOUT, depth, activation, critical_width=Nothing)\n",
    "# TO SEE ASCII ART OF LAYOUTS ↑↑↑\n",
    "\n",
    "### ----- IMPORTS\n",
    "using Flux\n",
    "include(\"DenseNTK.jl\")\n",
    "\n",
    "function model_architype(architype, dimIN, dimOUT, depth, activation, approx_num_params,critical_width=Nothing)\n",
    "    depth_validation(depth)\n",
    "\n",
    "    # Get appropriate width\n",
    "    if architype == \"LH1\"\n",
    "        widths = [dimIN, critical_width, dimOUT]\n",
    "        depth = 3\n",
    "    elseif architype == \"block\"\n",
    "        widths = widths_block(dimIN, dimOUT, depth, approx_num_params)\n",
    "    elseif architype == \"funnel\"\n",
    "        widths = widths_funnel(dimIN, dimIN, depth, approx_num_params)\n",
    "    elseif architype == \"reverse_funnel\"\n",
    "        widths = widths_reverse_funnel(dimIN, dimIN, depth, approx_num_params)\n",
    "    elseif architype == \"hourglass\"\n",
    "        widths = widths_hourglass(dimIN, dimOUT, depth, critical_width, approx_num_params)\n",
    "    elseif architype == \"diamond\"\n",
    "        widths = widths_diamond(dimIN, dimOUT, depth, critical_width, approx_num_params)\n",
    "    else\n",
    "        current_types = \"Current supported types:\\n\"\n",
    "        supported_types = [\"LH1\", \"block\", \"funnel\", \"reverse_funnel\", \"hourglass\", \"diamond\"]\n",
    "        error(\"'$architype' is not a valid architecture type\\n\\n$current_types$(join(supported_types, '\\n'))\\n\")\n",
    "    end\n",
    "\n",
    "    # Model construction\n",
    "    layers = []\n",
    "    if isa(activation, Function)\n",
    "        # All layers use the same activation function\n",
    "        for i in 1:depth-1\n",
    "            act = i < depth-1 ? activation : identity   # if i < depth-1 use activation else use identity function\n",
    "            push!(layers, DenseNTK(widths[i], widths[i+1], act))\n",
    "        end\n",
    "    elseif isa(activation, Vector)\n",
    "        # Different activation for each layer\n",
    "        do_activations_match_depth(depth, activation)\n",
    "        for i in 1:depth-1\n",
    "            act = i < depth-1 ? activation[i] : identity\n",
    "            push!(layers, DenseNTK(widths[i], widths[i+1], act))\n",
    "        end\n",
    "    else\n",
    "        error(\"Invalid activation type: must be a Function or Vector of Functions.\")\n",
    "    end\n",
    "\n",
    "    model = Chain(layers...)\n",
    "\n",
    "    return model\n",
    "end\n",
    "\n",
    "function construct_model(widths, activation)\n",
    "    # Model construction\n",
    "    layers = []\n",
    "    depth = length(widths)\n",
    "\n",
    "    if isa(activation, Function)\n",
    "        # All layers use the same activation function\n",
    "        for i in 1:depth-1\n",
    "            act = i < depth-1 ? activation : identity   # if i < depth-1 use activation else use identity function\n",
    "            push!(layers, DenseNTK(widths[i], widths[i+1], act))\n",
    "        end\n",
    "    elseif isa(activation, Vector)\n",
    "        # Different activation for each layer\n",
    "        do_activations_match_depth(depth, activation)\n",
    "        for i in 1:depth-1\n",
    "            act = i < depth-1 ? activation[i] : identity\n",
    "            push!(layers, DenseNTK(widths[i], widths[i+1], act))\n",
    "        end\n",
    "    else\n",
    "        error(\"Invalid activation type: must be a Function or Vector of Functions.\")\n",
    "    end\n",
    "\n",
    "    model = Chain(layers...)\n",
    "    return model\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  DenseNTK(Float32[-0.37557358; 0.48491597; … ; 0.30102775; -1.2416043;;], Float32[1.5125196, -0.33850855, -0.083546065, 0.0999315, 2.0458007, -0.94083095, -2.5482404, -0.9288291, -0.09738325, 0.099693835  …  -1.1703217, -0.4228017, -0.81690973, -0.5821124, 0.6065722, 1.0762348, -1.0848103, 0.8173694, -2.1110027, -1.7434909], NNlib.σ),  \u001b[90m# 334 parameters\u001b[39m\n",
       "  DenseNTK(Float32[1.200404 -1.9892446 … -1.3110242 1.316334; -0.15121916 -2.0997684 … 2.892227 0.685615; … ; 0.9470955 0.57674223 … -0.10624681 0.9021404; -0.53077334 -1.1780746 … -0.18228237 0.30758098], Float32[0.06752559, -0.6431602, -0.59302855, -0.19768971, 0.24681294, -0.50889575, 0.05497908, -1.2088491, -1.362163, 0.8213387  …  1.481869, 0.75512195, -0.7272934, -0.36818293, -0.5731397, -1.5194638, -0.2790977, -0.793775, 0.043785892, 0.10491545], NNlib.σ),  \u001b[90m# 28_056 parameters\u001b[39m\n",
       "  DenseNTK(Float32[-1.2654766 0.21954335 … 0.4437208 0.9263125; 0.43022233 -1.0366275 … 0.5155695 -0.24308722; … ; -1.6863629 -1.3010057 … 0.22133042 -0.57344353; 0.05265666 0.032511737 … 0.06127348 2.0196676], Float32[0.101479284, 0.41030395, -0.071984604, 0.97481704, 0.1679763, -0.15821946, 0.52986085, -1.6639404, -0.32467523, -1.1850197], identity),  \u001b[90m# 1_680 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m30_070 parameters, 117.906 KiB."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "function block(dimIN, dimOUT, depth, approx_num_params, activations)\n",
    "    widths = zeros(Int, depth)\n",
    "    widths[1] = dimIN\n",
    "    widths[end] = dimOUT\n",
    "    \n",
    "    quad_solve(a,b,c) = (-b+sqrt(b^2 - (4*a*c)))/(2*a)\n",
    "\n",
    "    # A B C fundin með algebru\n",
    "    A = depth-3\n",
    "    B = dimIN+1+dimOUT+depth-3\n",
    "    C = dimOUT-approx_num_params\n",
    "\n",
    "    nodes = Int(round(quad_solve(A,B,C)))\n",
    "    \n",
    "    for i = 2:(depth-1)\n",
    "        widths[i] = nodes\n",
    "    end\n",
    "\n",
    "    return construct_model(widths, activations)\n",
    "end\n",
    "\n",
    "dimIN = 1\n",
    "dimOUT = 10\n",
    "depth = 4\n",
    "params = 30_081\n",
    "\n",
    "\n",
    "block(dimIN, dimOUT, depth, params, [σ,σ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function widths_reverse_funnel(dimIN::Int, dimOUT::Int, depth::Int)\n",
    "    widths = zeros(Int, depth)\n",
    "    width_increment = (dimOUT - dimIN) / (depth - 1)\n",
    "\n",
    "    # Set the widths for each layer\n",
    "    for i in 1:depth\n",
    "        widths[i] = dimIN + round(Int, width_increment * (i - 1))\n",
    "    end\n",
    "\n",
    "    widths[1] = dimIN\n",
    "    widths[depth] = dimOUT\n",
    "\n",
    "    return widths\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function widths_hourglass(dimIN, dimOUT, depth, min_width)\n",
    "    widths = zeros(Int, depth) # n - Zero Vector\n",
    "    if depth%2 == 0\n",
    "        middle_layers = (depth ÷ 2, depth ÷ 2 + 1)\n",
    "        widths[middle_layers[1]], widths[middle_layers[2]] = min_width, min_width\n",
    "\n",
    "        # Calculate decrease and increase steps\n",
    "        decrease_step = (dimIN - min_width) / (middle_layers[1] - 1)\n",
    "        increase_step = (dimOUT - min_width) / (middle_layers[1] - 1)\n",
    "\n",
    "        # Set widths for decreasing and increasing phases\n",
    "        for i in 1:(middle_layers[1] - 1)\n",
    "            widths[i] = dimIN - round(Int, decrease_step * (i - 1))\n",
    "        end\n",
    "        for i in (middle_layers[2] + 1):depth\n",
    "            widths[i] = min_width + round(Int, increase_step * (i - middle_layers[2]))\n",
    "        end\n",
    "    else\n",
    "        middle_layer = ceil(Int, depth/2)\n",
    "        widths[middle_layer] = min_width\n",
    "\n",
    "        # Calculate decreasing widths from the input to the middle layer\n",
    "        decrease_step = (dimIN - min_width) / (middle_layer - 1)\n",
    "        for i in 1:(middle_layer-1)\n",
    "            widths[i] = dimIN - round(Int, decrease_step * (i - 1))\n",
    "        end\n",
    "\n",
    "        # Calculate increasing widths from the middle layer to the output\n",
    "        increase_step = (dimOUT - min_width) / (middle_layer - 1)\n",
    "        for i in (middle_layer+1):depth\n",
    "            widths[i] = min_width + round(Int, increase_step * (i - middle_layer))\n",
    "        end\n",
    "    end\n",
    "    widths[depth] = dimOUT\n",
    "\n",
    "    return widths\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function widths_diamond(dimIN::Int, dimOUT::Int, depth::Int, max_width::Int)\n",
    "    widths = zeros(Int, depth)\n",
    "\n",
    "    if depth % 2 == 1 #ODD\n",
    "        middle_index = ceil(Int, depth / 2)\n",
    "        widths[middle_index] = max_width\n",
    "\n",
    "        # Calculate width increments/decrements\n",
    "        expand_step = (max_width - dimIN) / (middle_index - 1)\n",
    "        contract_step = (max_width - dimOUT) / (middle_index - 1)\n",
    "        \n",
    "        # Set widths for expansion phase\n",
    "        for i in 1:(middle_index - 1)\n",
    "            widths[i] = dimIN + round(Int, expand_step * (i - 1))\n",
    "        end\n",
    "        # Set widths for contraction phase\n",
    "        for i in (middle_index + 1):depth\n",
    "            widths[i] = max_width - round(Int, contract_step * (i - middle_index))\n",
    "        end\n",
    "    \n",
    "    else #EVEN\n",
    "        middle_first = depth ÷ 2\n",
    "        middle_second = middle_first + 1\n",
    "        widths[middle_first], widths[middle_second] = max_width, max_width\n",
    "\n",
    "        # Calculate width increments/decrements\n",
    "        expand_step = (max_width - dimIN) / (middle_first - 1)\n",
    "        contract_step = (max_width - dimOUT) / (middle_first - 1)\n",
    "\n",
    "        # Set widths for expansion phase\n",
    "        for i in 1:(middle_first - 1)\n",
    "            widths[i] = dimIN + round(Int, expand_step * (i - 1))\n",
    "        end\n",
    "        # Set widths for contraction phase\n",
    "        for i in (middle_second + 1):depth\n",
    "            widths[i] = max_width - round(Int, contract_step * (i - middle_second))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    widths[1] = dimIN\n",
    "    widths[depth] = dimOUT\n",
    "\n",
    "    return widths\n",
    "end\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
