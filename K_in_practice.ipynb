{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"NTKernel.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSUDEO data\n",
    "g = x -> cos(2x)+sin(x/2)           # anonymous function g(x)\n",
    "\n",
    "X = range(1, stop=12, length=100)\n",
    "X = Matrix(reshape(X, 1, :))        # reshape, each column vector is read as data point\n",
    "\n",
    "Y = map(g,X);                       # Map with g(x)\n",
    "Ý = map_model(models[1],X);         # evaluates  the model on X and returns Ý, accounts for dim sizes 😍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes on hidden layer\n",
    "Nh = 100\n",
    "InputDim = 1\n",
    "activation = sigmoid\n",
    "\n",
    "model = Chain(Dense(InputDim=>Nh,activation),Dense(Nh=>InputDim))|>f64\n",
    "\n",
    "K = kernel(model, X)\n",
    "normalized_K = K / sqrt(Nh) # Normalize the kernel matrix\n",
    "\n",
    "λ_values = eigen(normalized_K).values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "# Create subplots\n",
    "plot1 = scatter(X[:], Y[:], label=\"Real data\", xlabel=\"X\", ylabel=\"Y\")\n",
    "scatter!(X[:], Ý[:], label=\"Estimated data\")\n",
    "\n",
    "plot2 = scatter(λ_values, label=\"Eigenvalue\", xlabel = \"Id. Eigenvalue\")\n",
    "\n",
    "# Combine subplots into a single plot\n",
    "plot(plot1, plot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Now, lets start tinkering with the models </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes on hidden layer\n",
    "Nh_list = [100] \n",
    "models = []\n",
    "activation = sigmoid\n",
    "\n",
    "InputDim = 1\n",
    "\n",
    "for Nh in 1:length(Nh_list)\n",
    "    push!(models,Chain(Dense(InputDim=>Nh_list[Nh],activation),Dense(Nh_list[Nh]=>InputDim))|>f64)\n",
    "end\n",
    "\n",
    "Kernels = []\n",
    "for model in models\n",
    "    push!(Kernels, kernel(model, X))\n",
    "end\n",
    "\n",
    "Kernels_Norms = []\n",
    "for (i, K) in enumerate(Kernels)\n",
    "    Nh = Nh_list[i] # Get the corresponding Nh for this kernel\n",
    "    normalized_K = K / sqrt(Nh) # Normalize the kernel matrix\n",
    "    push!(Kernels_Norms, normalized_K) # Store the normalized kernel\n",
    "end\n",
    "\n",
    "loss(a, b) = Flux.Losses.mse(models[1](a), b)\n",
    "#Flux.train!(loss, Flux.params(models[1]), [(X,Y)], Descent(0.01))\n",
    "\n",
    "λ_values = []\n",
    "for K in Kernels_Norms\n",
    "    push!(λ_values, eigen(K).values) # Compute eigenvalues for each kernel and store\n",
    "end\n",
    "\n",
    "λ_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
